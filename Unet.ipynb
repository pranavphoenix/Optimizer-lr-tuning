{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAQbuFTTJb7b",
        "outputId": "f0ed4bb5-7170-42bd-d8b8-3507886cae5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pydicom\n",
        "!pip install dicom\n",
        " \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        " \n",
        "%cd \"/content/drive/My Drive/TrainingSet\"\n",
        " \n",
        "#! git clone https://github.com/chuckyee/cardiac-segmentation.git  \n",
        " \n",
        "%cd cardiac-segmentation\n",
        "#!pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: dicom in /usr/local/lib/python3.6/dist-packages (0.9.9.post1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/.shortcut-targets-by-id/15_bncqiTE7-hHuSb3jG-DtFgbMx_k45P/TrainingSet\n",
            "/content/drive/.shortcut-targets-by-id/15_bncqiTE7-hHuSb3jG-DtFgbMx_k45P/TrainingSet/cardiac-segmentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kKNBIztKSsn",
        "outputId": "c4f4e0a3-ef87-43e8-de22-42313e852661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "from __future__ import division, print_function\n",
        "\n",
        "from math import ceil\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "\n",
        "from keras import utils\n",
        "from keras.preprocessing import image as keras_image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os, glob, re\n",
        "import dicom\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose\n",
        "from keras.layers import MaxPooling2D, Cropping2D, Concatenate\n",
        "from keras.layers import Lambda, Activation, BatchNormalization, Dropout\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "from keras import losses, optimizers, utils\n",
        "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "def maybe_rotate(image):\n",
        "    # orient image in landscape\n",
        "    height, width = image.shape\n",
        "    return np.rot90(image) if width < height else image\n",
        "\n",
        "class PatientData(object):\n",
        "    \"\"\"Data directory structure (for patient 01):\n",
        "    directory/\n",
        "      P01dicom.txt\n",
        "      P01dicom/\n",
        "        P01-0000.dcm\n",
        "        P01-0001.dcm\n",
        "        ...\n",
        "      P01contours-manual/\n",
        "        P01-0080-icontour-manual.txt\n",
        "        P01-0120-ocontour-manual.txt\n",
        "        ...\n",
        "    \"\"\"\n",
        "    def __init__(self, directory):\n",
        "        self.directory = os.path.normpath(directory)\n",
        "\n",
        "        # get patient index from contour listing file\n",
        "        glob_search = os.path.join(directory, \"P*list.txt\")\n",
        "        files = glob.glob(glob_search)\n",
        "        if len(files) == 0:\n",
        "            raise Exception(\"Couldn't find contour listing file in {}. \"\n",
        "                            \"Wrong directory?\".format(directory))\n",
        "        self.contour_list_file = files[0]\n",
        "        match = re.search(\"P(..)list.txt\", self.contour_list_file)\n",
        "        self.index = int(match.group(1))\n",
        "\n",
        "        # load all data into memory\n",
        "        self.load_images()\n",
        "\n",
        "        # some patients do not have contour data, and that's ok\n",
        "        try:\n",
        "            self.load_masks()\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "\n",
        "    @property\n",
        "    def images(self):\n",
        "        return [self.all_images[i] for i in self.labeled]\n",
        "\n",
        "    @property\n",
        "    def dicoms(self):\n",
        "        return [self.all_dicoms[i] for i in self.labeled]\n",
        "\n",
        "    @property\n",
        "    def dicom_path(self):\n",
        "        return os.path.join(self.directory, \"P{:02d}dicom\".format(self.index))\n",
        "\n",
        "    def load_images(self):\n",
        "        glob_search = os.path.join(self.dicom_path, \"*.dcm\")\n",
        "        dicom_files = sorted(glob.glob(glob_search))\n",
        "        self.all_images = []\n",
        "        self.all_dicoms = []\n",
        "        for dicom_file in dicom_files:\n",
        "            plan = dicom.read_file(dicom_file)\n",
        "            image = maybe_rotate(plan.pixel_array)\n",
        "            self.all_images.append(image)\n",
        "            self.all_dicoms.append(plan)\n",
        "        self.image_height, self.image_width = image.shape\n",
        "        self.rotated = (plan.pixel_array.shape != image.shape)\n",
        "\n",
        "    def load_contour(self, filename):\n",
        "        # strip out path head \"patientXX/\"\n",
        "        match = re.search(\"patient../(.*)\", filename)\n",
        "        path = os.path.join(self.directory, match.group(1))\n",
        "        x, y = np.loadtxt(path).T\n",
        "        if self.rotated:\n",
        "            x, y = y, self.image_height - x\n",
        "        return x, y\n",
        "\n",
        "    def contour_to_mask(self, x, y, norm=255):\n",
        "        BW_8BIT = 'L'\n",
        "        polygon = list(zip(x, y))\n",
        "        image_dims = (self.image_width, self.image_height)\n",
        "        img = Image.new(BW_8BIT, image_dims, color=0)\n",
        "        ImageDraw.Draw(img).polygon(polygon, outline=1, fill=1)\n",
        "        return norm * np.array(img, dtype='uint8')\n",
        "\n",
        "    def load_masks(self):\n",
        "        with open(self.contour_list_file, 'r') as f:\n",
        "            files = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        inner_files = [path.replace(\"\\\\\", \"/\") for path in files[0::2]]\n",
        "        outer_files = [path.replace(\"\\\\\", \"/\") for path in files[1::2]]\n",
        "\n",
        "        # get list of frames which have contours\n",
        "        self.labeled = []\n",
        "        for inner_file in inner_files:\n",
        "            match = re.search(\"P..-(....)-.contour\", inner_file)\n",
        "            frame_number = int(match.group(1))\n",
        "            self.labeled.append(frame_number)\n",
        "\n",
        "        self.endocardium_contours = []\n",
        "        self.epicardium_contours = []\n",
        "        self.endocardium_masks = []\n",
        "        self.epicardium_masks = []\n",
        "        for inner_file, outer_file in zip(inner_files, outer_files):\n",
        "            inner_x, inner_y = self.load_contour(inner_file)\n",
        "            self.endocardium_contours.append((inner_x, inner_y))\n",
        "            outer_x, outer_y = self.load_contour(outer_file)\n",
        "            self.epicardium_contours.append((outer_x, outer_y))\n",
        "\n",
        "            inner_mask = self.contour_to_mask(inner_x, inner_y, norm=1)\n",
        "            self.endocardium_masks.append(inner_mask)\n",
        "            outer_mask = self.contour_to_mask(outer_x, outer_y, norm=1)\n",
        "            self.epicardium_masks.append(outer_mask)\n",
        "            \n",
        "    def write_video(self, outfile, FPS=24):\n",
        "        import cv2\n",
        "        image_dims = (self.image_width, self.image_height)\n",
        "        video = cv2.VideoWriter(outfile, -1, FPS, image_dims)\n",
        "        for image in self.all_images:\n",
        "            grayscale = np.asarray(image * (255 / image.max()), dtype='uint8')\n",
        "            video.write(cv2.cvtColor(grayscale, cv2.COLOR_GRAY2BGR))\n",
        "        video.release()\n",
        "\n",
        "def load_images(data_dir, mask='both'):\n",
        "    \"\"\"Load all patient images and contours from TrainingSet, Test1Set or\n",
        "    Test2Set directory. The directories and images are read in sorted order.\n",
        "\n",
        "    Arguments:\n",
        "      data_dir - path to data directory (TrainingSet, Test1Set or Test2Set)\n",
        "\n",
        "    Output:\n",
        "      tuples of (images, masks), both of which are 4-d tensors of shape\n",
        "      (batchsize, height, width, channels). Images is uint16 and masks are\n",
        "      uint8 with values 0 or 1.\n",
        "    \"\"\"\n",
        "    assert mask in ['inner', 'outer', 'both']\n",
        "\n",
        "    glob_search = os.path.join(data_dir, \"patient*\")\n",
        "    patient_dirs = sorted(glob.glob(glob_search))\n",
        "    if len(patient_dirs) == 0:\n",
        "        raise Exception(\"No patient directors found in {}\".format(data_dir))\n",
        "\n",
        "    # load all images into memory (dataset is small)\n",
        "    images = []\n",
        "    inner_masks = []\n",
        "    outer_masks = []\n",
        "    for patient_dir in patient_dirs :\n",
        "        p = PatientData(patient_dir)\n",
        "        images += p.images\n",
        "        inner_masks += p.endocardium_masks\n",
        "        outer_masks += p.epicardium_masks\n",
        "\n",
        "    # reshape to account for channel dimension\n",
        "    images = np.asarray(images)[:,:,:,None]\n",
        "    if mask == 'inner':\n",
        "        masks = np.asarray(inner_masks)\n",
        "    elif mask == 'outer':\n",
        "        masks = np.asarray(outer_masks)\n",
        "    elif mask == 'both':\n",
        "        # mask = 2 for endocardium, 1 for cardiac wall, 0 elsewhere\n",
        "        masks = np.asarray(inner_masks) + np.asarray(outer_masks)\n",
        "\n",
        "    # one-hot encode masks\n",
        "    dims = masks.shape\n",
        "    classes = len(set(masks[0].flatten())) # get num classes from first image\n",
        "    new_shape = dims + (classes,)\n",
        "    masks = utils.to_categorical(masks).reshape(new_shape)\n",
        "\n",
        "    return images, masks\n",
        "\n",
        "def random_elastic_deformation(image, alpha, sigma, mode='nearest',\n",
        "                               random_state=None):\n",
        "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
        "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
        "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
        "       Proc. of the International Conference on Document Analysis and\n",
        "       Recognition, 2003.\n",
        "    \"\"\"\n",
        "    assert len(image.shape) == 3\n",
        "\n",
        "    if random_state is None:\n",
        "        random_state = np.random.RandomState(None)\n",
        "\n",
        "    height, width, channels = image.shape\n",
        "\n",
        "    dx = gaussian_filter(2*random_state.rand(height, width) - 1,\n",
        "                         sigma, mode=\"constant\", cval=0) * alpha\n",
        "    dy = gaussian_filter(2*random_state.rand(height, width) - 1,\n",
        "                         sigma, mode=\"constant\", cval=0) * alpha\n",
        "\n",
        "    x, y = np.meshgrid(np.arange(height), np.arange(width), indexing='ij')\n",
        "    indices = (np.repeat(np.ravel(x+dx), channels),\n",
        "               np.repeat(np.ravel(y+dy), channels),\n",
        "               np.tile(np.arange(channels), height*width))\n",
        "    \n",
        "    values = map_coordinates(image, indices, order=1, mode=mode)\n",
        "\n",
        "    return values.reshape((height, width, channels))\n",
        "\n",
        "class Iterator(object):\n",
        "    def __init__(self, images, masks, batch_size,\n",
        "                 shuffle=True,\n",
        "                 rotation_range=180,\n",
        "                 width_shift_range=0.1,\n",
        "                 height_shift_range=0.1,\n",
        "                 shear_range=0.1,\n",
        "                 zoom_range=0.01,\n",
        "                 fill_mode='nearest',\n",
        "                 alpha=500,\n",
        "                 sigma=20):\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        augment_options = {\n",
        "            'rotation_range': rotation_range,\n",
        "            'width_shift_range': width_shift_range,\n",
        "            'height_shift_range': height_shift_range,\n",
        "            'shear_range': shear_range,\n",
        "            'zoom_range': zoom_range,\n",
        "            'fill_mode': fill_mode,\n",
        "        }\n",
        "        self.idg = ImageDataGenerator(**augment_options)\n",
        "        self.alpha = alpha\n",
        "        self.sigma = sigma\n",
        "        self.fill_mode = fill_mode\n",
        "        self.i = 0\n",
        "        self.index = np.arange(len(images))\n",
        "        if shuffle:\n",
        "            np.random.shuffle(self.index)\n",
        "\n",
        "    def __next__(self):\n",
        "        return self.next()\n",
        "\n",
        "    def next(self):\n",
        "        # compute how many images to output in this batch\n",
        "        start = self.i\n",
        "        end = min(start + self.batch_size, len(self.images))\n",
        "\n",
        "        augmented_images = []\n",
        "        augmented_masks = []\n",
        "        for n in self.index[start:end]:\n",
        "            image = self.images[n]\n",
        "            mask = self.masks[n]\n",
        "\n",
        "            _, _, channels = image.shape\n",
        "\n",
        "            # stack image + mask together to simultaneously augment\n",
        "            stacked = np.concatenate((image, mask), axis=2)\n",
        "\n",
        "            # apply simple affine transforms first using Keras\n",
        "            augmented = self.idg.random_transform(stacked)\n",
        "\n",
        "            # maybe apply elastic deformation\n",
        "            if self.alpha != 0 and self.sigma != 0:\n",
        "                augmented = random_elastic_deformation(\n",
        "                    augmented, self.alpha, self.sigma, self.fill_mode)\n",
        "\n",
        "            # split image and mask back apart\n",
        "            augmented_image = augmented[:,:,:channels]\n",
        "            augmented_images.append(augmented_image)\n",
        "            augmented_mask = np.round(augmented[:,:,channels:])\n",
        "            augmented_masks.append(augmented_mask)\n",
        "\n",
        "        self.i += self.batch_size\n",
        "        if self.i >= len(self.images):\n",
        "            self.i = 0\n",
        "            if self.shuffle:\n",
        "                np.random.shuffle(self.index)\n",
        "\n",
        "        return np.asarray(augmented_images), np.asarray(augmented_masks)\n",
        "\n",
        "def normalize(x, epsilon=1e-7, axis=(1,2)):\n",
        "    x -= np.mean(x, axis=axis, keepdims=True)\n",
        "    x /= np.std(x, axis=axis, keepdims=True) + epsilon\n",
        "\n",
        "def create_generators(data_dir, batch_size, validation_split=0.0, mask='both',\n",
        "                      shuffle_train_val=True, shuffle=True, seed=None,\n",
        "                      normalize_images=True, augment_training=False,\n",
        "                      augment_validation=False, augmentation_args={}):\n",
        "    images, masks = load_images(data_dir, mask)\n",
        "\n",
        "    # before: type(masks) = uint8 and type(images) = uint16\n",
        "    # convert images to double-precision\n",
        "    images = images.astype('float64')\n",
        "\n",
        "    # maybe normalize image\n",
        "    if normalize_images:\n",
        "        normalize(images, axis=(1,2))\n",
        "\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    if shuffle_train_val:\n",
        "        # shuffle images and masks in parallel\n",
        "        rng_state = np.random.get_state()\n",
        "        np.random.shuffle(images)\n",
        "        np.random.set_state(rng_state)\n",
        "        np.random.shuffle(masks)\n",
        "\n",
        "    # split out last %(validation_split) of images as validation set\n",
        "    split_index = int((1-validation_split) * len(images))\n",
        "\n",
        "    if augment_training:\n",
        "        train_generator = Iterator(\n",
        "            images[:split_index], masks[:split_index],\n",
        "            batch_size, shuffle=shuffle, **augmentation_args)\n",
        "    else:\n",
        "        idg = ImageDataGenerator()\n",
        "        train_generator = idg.flow(images[:split_index], masks[:split_index],\n",
        "                                   batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    train_steps_per_epoch = ceil(split_index / batch_size)\n",
        "\n",
        "    if validation_split > 0.0:\n",
        "        if augment_validation:\n",
        "            val_generator = Iterator(\n",
        "                images[split_index:], masks[split_index:],\n",
        "                batch_size, shuffle=shuffle, **augmentation_args)\n",
        "        else:\n",
        "            idg = ImageDataGenerator()\n",
        "            val_generator = idg.flow(images[split_index:], masks[split_index:],\n",
        "                                     batch_size=batch_size, shuffle=shuffle)\n",
        "    else:\n",
        "        val_generator = None\n",
        "\n",
        "    val_steps_per_epoch = ceil((len(images) - split_index) / batch_size)\n",
        "\n",
        "    return (train_generator, train_steps_per_epoch,\n",
        "            val_generator, val_steps_per_epoch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dicom/__init__.py:53: UserWarning: \n",
            "This code is using an older version of pydicom, which is no longer \n",
            "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
            "by installing `pydicom` from PyPI.\n",
            "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
            "for more information.\n",
            "\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3KpElnLK1Om"
      },
      "source": [
        "def downsampling_block(input_tensor, filters, padding='valid',\n",
        "                       batchnorm=False, dropout=0.0):\n",
        "    _, height, width, _ = K.int_shape(input_tensor)\n",
        "    \n",
        "    assert height % 2 == 0\n",
        "    assert width % 2 == 0\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=(3,3), padding=padding)(input_tensor)\n",
        "    x = BatchNormalization()(x) if batchnorm else x\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=(3,3), padding=padding)(x)\n",
        "    x = BatchNormalization()(x) if batchnorm else x\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
        "\n",
        "    return MaxPooling2D(pool_size=(2,2))(x), x\n",
        "\n",
        "def upsampling_block(input_tensor, skip_tensor, filters, padding='valid',\n",
        "                     batchnorm=False, dropout=0.0):\n",
        "    x = Conv2DTranspose(filters, kernel_size=(2,2), strides=(2,2))(input_tensor)\n",
        "\n",
        "    # compute amount of cropping needed for skip_tensor\n",
        "    _, x_height, x_width, _ = K.int_shape(x)\n",
        "    _, s_height, s_width, _ = K.int_shape(skip_tensor)\n",
        "    h_crop = s_height - x_height\n",
        "    w_crop = s_width - x_width\n",
        "    assert h_crop >= 0\n",
        "    assert w_crop >= 0\n",
        "    if h_crop == 0 and w_crop == 0:\n",
        "        y = skip_tensor\n",
        "    else:\n",
        "        cropping = ((h_crop//2, h_crop - h_crop//2), (w_crop//2, w_crop - w_crop//2))\n",
        "        y = Cropping2D(cropping=cropping)(skip_tensor)\n",
        "\n",
        "    x = Concatenate()([x, y])\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=(3,3), padding=padding)(x)\n",
        "    x = BatchNormalization()(x) if batchnorm else x\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=(3,3), padding=padding)(x)\n",
        "    x = BatchNormalization()(x) if batchnorm else x\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
        "\n",
        "    return x\n",
        "\n",
        "def unet(height, width, channels, classes, features=64, depth=3,\n",
        "         temperature=1.0, padding='valid', batchnorm=False, dropout=0.0):\n",
        "    \"\"\"Generate U-Net model introduced in\n",
        "      \"U-Net: Convolutional Networks for Biomedical Image Segmentation\"\n",
        "      O. Ronneberger, P. Fischer, T. Brox (2015)\n",
        "    Arbitrary number of input channels and output classes are supported.\n",
        "\n",
        "    Arguments:\n",
        "      height  - input image height (pixels)\n",
        "      width   - input image width  (pixels)\n",
        "      channels - input image features (1 for grayscale, 3 for RGB)\n",
        "      classes - number of output classes (2 in paper)\n",
        "      features - number of output features for first convolution (64 in paper)\n",
        "          Number of features double after each down sampling block\n",
        "      depth  - number of downsampling operations (4 in paper)\n",
        "      padding - 'valid' (used in paper) or 'same'\n",
        "      batchnorm - include batch normalization layers before activations\n",
        "      dropout - fraction of units to dropout, 0 to keep all units\n",
        "\n",
        "    Output:\n",
        "      U-Net model expecting input shape (height, width, maps) and generate\n",
        "      output with shape (output_height, output_width, classes). If padding is\n",
        "      'same', then output_height = height and output_width = width.\n",
        "    \"\"\"\n",
        "    x = Input(shape=(height, width, channels))\n",
        "    inputs = x\n",
        "\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x, x0 = downsampling_block(x, features, padding,\n",
        "                                   batchnorm, dropout)\n",
        "        skips.append(x0)\n",
        "        features *= 2\n",
        "\n",
        "    x = Conv2D(filters=features, kernel_size=(3,3), padding=padding)(x)\n",
        "    x = BatchNormalization()(x) if batchnorm else x\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
        "\n",
        "    x = Conv2D(filters=features, kernel_size=(3,3), padding=padding)(x)\n",
        "    x = BatchNormalization()(x) if batchnorm else x\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features //= 2\n",
        "        x = upsampling_block(x, skips[i], features, padding,\n",
        "                             batchnorm, dropout)\n",
        "\n",
        "    x = Conv2D(filters=classes, kernel_size=(1,1))(x)\n",
        "\n",
        "    logits = Lambda(lambda z: z/temperature)(x)\n",
        "    probabilities = Activation('softmax')(logits)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=probabilities)\n",
        "\n",
        "def soft_sorensen_dice(y_true, y_pred, axis=None, smooth=1):\n",
        "    intersection = K.sum(y_true * y_pred, axis=axis)\n",
        "    area_true = K.sum(y_true, axis=axis)\n",
        "    area_pred = K.sum(y_pred, axis=axis)\n",
        "    return (2 * intersection + smooth) / (area_true + area_pred + smooth)\n",
        "    \n",
        "def hard_sorensen_dice(y_true, y_pred, axis=None, smooth=1):\n",
        "    y_true_int = K.round(y_true)\n",
        "    y_pred_int = K.round(y_pred)\n",
        "    return soft_sorensen_dice(y_true_int, y_pred_int, axis, smooth)\n",
        "\n",
        "sorensen_dice = hard_sorensen_dice\n",
        "\n",
        "def sorensen_dice_loss(y_true, y_pred, weights):\n",
        "    # Input tensors have shape (batch_size, height, width, classes)\n",
        "    # User must input list of weights with length equal to number of classes\n",
        "    #\n",
        "    # Ex: for simple binary classification, with the 0th mask\n",
        "    # corresponding to the background and the 1st mask corresponding\n",
        "    # to the object of interest, we set weights = [0, 1]\n",
        "    batch_dice_coefs = soft_sorensen_dice(y_true, y_pred, axis=[1, 2])\n",
        "    dice_coefs = K.mean(batch_dice_coefs, axis=0)\n",
        "    w = K.constant(weights) / sum(weights)\n",
        "    return 1 - K.sum(w * dice_coefs)\n",
        "\n",
        "def soft_jaccard(y_true, y_pred, axis=None, smooth=1):\n",
        "    intersection = K.sum(y_true * y_pred, axis=axis)\n",
        "    area_true = K.sum(y_true, axis=axis)\n",
        "    area_pred = K.sum(y_pred, axis=axis)\n",
        "    union = area_true + area_pred - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "def hard_jaccard(y_true, y_pred, axis=None, smooth=1):\n",
        "    y_true_int = K.round(y_true)\n",
        "    y_pred_int = K.round(y_pred)\n",
        "    return soft_jaccard(y_true_int, y_pred_int, axis, smooth)\n",
        "\n",
        "jaccard = hard_jaccard\n",
        "\n",
        "def jaccard_loss(y_true, y_pred, weights):\n",
        "    batch_jaccard_coefs = soft_jaccard(y_true, y_pred, axis=[1, 2])\n",
        "    jaccard_coefs = K.mean(batch_jaccard_coefs, axis=0)\n",
        "    w = K.constant(weights) / sum(weights)\n",
        "    return 1 - K.sum(w * jaccard_coefs)\n",
        "\n",
        "def weighted_categorical_crossentropy(y_true, y_pred, weights, epsilon=1e-8):\n",
        "    ndim = K.ndim(y_pred)\n",
        "    ncategory = K.int_shape(y_pred)[-1]\n",
        "    # scale predictions so class probabilities of each pixel sum to 1\n",
        "    y_pred /= K.sum(y_pred, axis=(ndim-1), keepdims=True)\n",
        "    y_pred = K.clip(y_pred, epsilon, 1-epsilon)\n",
        "    w = K.constant(weights) * (ncategory / sum(weights))\n",
        "    # first, average over all axis except classes\n",
        "    cross_entropies = -K.mean(y_true * K.log(y_pred), axis=tuple(range(ndim-1)))\n",
        "    return K.sum(w * cross_entropies)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nlN95BWxQ3T"
      },
      "source": [
        "\n",
        "datadir = \"/content/drive/My Drive/TrainingSet/cardiac-segmentation\" # Directory containing list of patientXX/ subdirectories\n",
        "outdir = \"/content/drive/My Drive/TrainingSet/cardiac-segmentation\"  # Where to write weight files\n",
        "outfile = 'weights-final.hdf5'                                       # File to write final model weights\n",
        "testdir =  \"/content/drive/My Drive/Test1Set\"\n",
        "\n",
        "augmentation_args = {\n",
        "        'rotation_range': 180,       # Rotation range (0-180 degrees)\n",
        "        'width_shift_range': 0.1,    # Width shift range, as a float fraction of the width\n",
        "        'height_shift_range': 0.1,   # Height shift range, as a float fraction of the height\n",
        "        'shear_range': 0.1,          # Shear intensity (in radians)\n",
        "        'zoom_range': 0.05,          # Amount of zoom. If a scalar z, zoom in [1-z, 1+z].Can also pass a pair of floats as the zoom range.\n",
        "        'fill_mode' :'nearest',      # Points outside boundaries are filled according to  mode: constant, nearest, reflect, or wrap)\n",
        "        'alpha': 500,                # Random elastic distortion: magnitude of distortion\n",
        "        'sigma': 20,                 # Random elastic distortion: length scale\n",
        "    }\n",
        "batch_size = 32               # Mini-batch size for training\n",
        "validation_split = 0.2        # Fraction of training data to hold out for validation\n",
        "shuffle_train_val = False\n",
        "classes = 'inner'           # One of `inner', `outer', or `both' for endocardium, epicardium, or both\n",
        "shuffle = False\n",
        "seed = 1\n",
        "normalize = False\n",
        "augment_training= False       # Whether to apply image augmentation to training set\n",
        "augment_validation = False    # Whether to apply image augmentation to validation set\n",
        "\n",
        "train_generator, train_steps_per_epoch, \\\n",
        "        val_generator, val_steps_per_epoch = create_generators(\n",
        "            datadir, batch_size,\n",
        "            validation_split=validation_split,\n",
        "            mask=classes,\n",
        "            shuffle_train_val=shuffle_train_val,\n",
        "            shuffle=shuffle,\n",
        "            seed=seed,\n",
        "            normalize_images=normalize,\n",
        "            augment_training=augment_training,\n",
        "            augment_validation=augment_validation,\n",
        "            augmentation_args=augmentation_args)\n",
        "\n",
        "images, masks = next(train_generator)\n",
        "_, height, width, channels = images.shape\n",
        "_, _, _, classes = masks.shape\n",
        "\n",
        "test_generator, test_steps_per_epoch, \\\n",
        "        test_val_generator, test_val_steps_per_epoch = create_generators(\n",
        "            testdir, 64,\n",
        "            validation_split=0.0,\n",
        "            mask='inner',\n",
        "            shuffle_train_val=False,\n",
        "            shuffle=False,\n",
        "            seed=None,\n",
        "            normalize_images=False,\n",
        "            augment_training=False,\n",
        "            augment_validation=False,\n",
        "            augmentation_args=augmentation_args) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2oCoP1EajeV"
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "def weighted_bce_loss(y_true, y_pred, weight):\n",
        "    epsilon = 1e-7\n",
        "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
        "    loss = weight * (logit_y_pred * (1. - y_true) + \n",
        "                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
        "    return K.sum(loss) / K.sum(weight)\n",
        "\n",
        "\n",
        "def weighted_dice_loss(y_true, y_pred, weight):\n",
        "    smooth = 1.\n",
        "    w, m1, m2 = weight, y_true, y_pred\n",
        "    intersection = (m1 * m2)\n",
        "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
        "    loss = 1. - K.sum(score)\n",
        "    return loss\n",
        "\n",
        "def weighted_bce_dice_loss(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    # if we want to get same size of output, kernel size must be odd\n",
        "    averaged_mask = K.pool2d(\n",
        "            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
        "    weight = K.ones_like(averaged_mask)\n",
        "    w0 = K.sum(weight)\n",
        "    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
        "    w1 = K.sum(weight)\n",
        "    weight *= (w0 / w1)\n",
        "    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
        "    return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cvy65USTPXL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)\n",
        "\n",
        "callback = keras.callbacks.LearningRateScheduler(scheduler)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seWjMvKplCDm",
        "outputId": "8bfc3798-0f83-4a3c-b193-ffd488d7d873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        }
      },
      "source": [
        "def select_optimizer(optimizer_name, optimizer_args):\n",
        "    optimizers = {\n",
        "        'sgd': SGD,\n",
        "        'rmsprop': RMSprop,\n",
        "        'adagrad': Adagrad,\n",
        "        'adadelta': Adadelta,\n",
        "        'adam': Adam,\n",
        "        'adamax': Adamax,\n",
        "        'nadam': Nadam,\n",
        "    }\n",
        "    if optimizer_name not in optimizers:\n",
        "        raise Exception(\"Unknown optimizer ({}).\".format(name))\n",
        "    return optimizers[optimizer_name](**optimizer_args)    \n",
        "      \n",
        "    # get image dimensions from first batch\n",
        "\n",
        "features = 64          # Number of features maps after first convolutional layer\n",
        "depth = 3              # Number of downsampled convolutional blocks\n",
        "temperature = 1.0      # Temperature of final softmax layer in model\n",
        "padding = 'same'       # Padding in convolutional layers. Either `same' or `valid'\n",
        "dropout = 0.02         # Rate for dropout of activation units (set to zero to omit)\n",
        "batchnorm = False      # Whether to apply batch normalization before activation layers\n",
        "   \n",
        "m = unet(height=height, width=width, channels=channels, classes=classes,\n",
        "              features=features, depth=depth, padding=padding,\n",
        "              temperature=temperature, batchnorm=batchnorm,\n",
        "              dropout=dropout)\n",
        "\n",
        "learning_rate = 0.1\n",
        "momentum = None\n",
        "decay = None\n",
        "optimizer = 'adam'               # Optimizer: sgd, rmsprop, adagrad, adadelta, adam, adamax, or nadam\n",
        "optimizer_args = {\n",
        "        'lr':       learning_rate,   # Optimizer learning rate\n",
        "        'momentum': momentum,        # Momentum for SGD optimizer\n",
        "        'decay':    decay            # Learning rate decay (for all optimizers except nadam)\n",
        "    }\n",
        "for k in list(optimizer_args):\n",
        "    if optimizer_args[k] is None:\n",
        "        del optimizer_args[k]\n",
        "optimizer = select_optimizer(optimizer, optimizer_args)\n",
        "\n",
        "loss = 'dice'               # Loss function: `pixel' for pixel-wise cross entropy,\n",
        "                                 # `dice' for sorensen-dice coefficient,\n",
        "                                 # `jaccard' for intersection over union\n",
        "loss_weights = [0.1, 0.9]    # When using dice or jaccard loss, how much to weight each output class\n",
        "\n",
        "if loss == 'pixel':\n",
        "    def lossfunc(y_true, y_pred):\n",
        "        return weighted_categorical_crossentropy(\n",
        "                y_true, y_pred, loss_weights)\n",
        "elif loss == 'dice':\n",
        "    def lossfunc(y_true, y_pred):\n",
        "        return dice_loss(y_true, y_pred)\n",
        "elif loss == 'jaccard':\n",
        "    def lossfunc(y_true, y_pred):\n",
        "        return jaccard_loss(y_true, y_pred, loss_weights)\n",
        "else:\n",
        "    raise Exception(\"Unknown loss ({})\".format(loss))\n",
        "def dice(y_true, y_pred):\n",
        "    batch_dice_coefs = sorensen_dice(y_true, y_pred, axis=[1, 2])\n",
        "    dice_coefs = K.mean(batch_dice_coefs, axis=0)\n",
        "    return dice_coefs[1]    # HACK for 2-class case\n",
        "def jaccard(y_true, y_pred):\n",
        "    batch_jaccard_coefs = jaccard(y_true, y_pred, axis=[1, 2])\n",
        "    jaccard_coefs = K.mean(batch_jaccard_coefs, axis=0)\n",
        "    return jaccard_coefs[1] # HACK for 2-class case\n",
        "\n",
        "import keras\n",
        "\n",
        "metrics = ['accuracy', keras.metrics.MeanIoU(num_classes=2), dice_coef]\n",
        "m.compile(optimizer=optimizer, loss=lossfunc, metrics=metrics)\n",
        "    # automatic saving of model during training\n",
        "checkpoint = False\n",
        "if checkpoint:\n",
        "    if loss == 'pixel':\n",
        "        filepath = os.path.join(\n",
        "                outdir, \"weights-{epoch:02d}-{val_acc:.4f}.hdf5\")\n",
        "        monitor = 'val_acc'\n",
        "        mode = 'max'\n",
        "    elif loss == 'dice':\n",
        "        filepath = os.path.join(\n",
        "                outdir, \"weights-{epoch:02d}-{val_dice:.4f}.hdf5\")\n",
        "        monitor='val_dice'\n",
        "        mode = 'max'\n",
        "    elif loss == 'jaccard':\n",
        "        filepath = os.path.join(\n",
        "                outdir, \"weights-{epoch:02d}-{val_jaccard:.4f}.hdf5\")\n",
        "        monitor='val_jaccard'\n",
        "        mode = 'max'\n",
        "    checkpoint = ModelCheckpoint(\n",
        "            filepath, monitor=monitor, verbose=1,\n",
        "            save_best_only=True, mode=mode)\n",
        "    callbacks = [checkpoint]\n",
        "else:\n",
        "    callbacks = []\n",
        "    # train\n",
        "\n",
        "epochs = 3  # Number of epochs to train\n",
        "    \n",
        "m.fit_generator(train_generator,\n",
        "                    epochs=epochs,\n",
        "                    steps_per_epoch=train_steps_per_epoch,\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps=val_steps_per_epoch,\n",
        "                    callbacks=[callback],\n",
        "                    verbose=2)\n",
        "# m.save(os.path.join(outdir, outfile))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-631af46ed832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     verbose=2)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;31m# m.save(os.path.join(outdir, outfile))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[32,128,108,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node functional_9/conv2d_transpose_13/conv2d_transpose (defined at <ipython-input-15-631af46ed832>:107) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[confusion_matrix/stack_1/_88]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[32,128,108,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node functional_9/conv2d_transpose_13/conv2d_transpose (defined at <ipython-input-15-631af46ed832>:107) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_17388]\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UW5gPsdQO5V",
        "outputId": "f45350b6-7917-4d9f-a298-6fa2205b0e1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "m.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 657ms/step - loss: 0.0491 - accuracy: 0.9509 - mean_io_u_1: 0.9063 - dice_coef: 0.9559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.049127332866191864,\n",
              " 0.9508726596832275,\n",
              " 0.9063462615013123,\n",
              " 0.9558917284011841]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTRvXtUY0ncn"
      },
      "source": [
        "def sorensen_dice(y_true, y_pred):\n",
        "    intersection = np.sum(y_true * y_pred)\n",
        "    return 2*intersection / (np.sum(y_true) + np.sum(y_pred))\n",
        "\n",
        "def jaccard(y_true, y_pred):\n",
        "    intersection = np.sum(y_true & y_pred)\n",
        "    union = np.sum(y_true | y_pred)\n",
        "    return intersection / union"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}